{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAG3CAIAAAAmefbtAAAKqWlDQ1BJQ0MgUHJvZmlsZQAASImVlwdQU1kXgO97L52ElhA6hN4E6QSQEkILRZAONkISIJQQA0HEjiyuwFpQEQEbuiqi4KoUWSuiWFgUVLAvyKKgrGLBhsr/gCHs7j///89/3pw53zvv3HPPvXPvzHkAUBS5YnEarAhAuihLEubnxYiJjWPgBwECFNHHHFC5vEwxKzQ0CKAybf8uH7oBNGFvW07k+vfv/1WU+IJMHgBQKMoJ/ExeOsqnUH3BE0uyAED2on6DpVniCW5FmSZBC0T53gQnTfHwBCdMMgZMxkSEsVGmAUAgc7mSJADIDNTPyOYloXnInihbi/hCEcpilN3T0zP4KB9H2RSNQX3kifzMhL/kSfpbzgRZTi43ScZTa5kUgrcwU5zGXfZ/bsf/lvQ06fQcxqiSkyX+YahVRvfsXmpGoIxFCXNDplnIn4yf5GSpf+Q08zLZcdPM53oHysamzQ2a5kShL0eWJ4sTMc2CTJ/waZZkhMnmSpSwWdPMlczMK02NlPmTBRxZ/tzkiOhpzhZGzZ3mzNTwwJkYtswvkYbJ6heI/Lxm5vWVrT098y/rFXJkY7OSI/xla+fO1C8QsWZyZsbIauMLvH1mYiJl8eIsL9lc4rRQWbwgzU/mz8wOl43NQg/kzNhQ2R6mcANCpxmwQQZIQ1UCGCAIffMGIEuQkzWxEHaGeJlEmJScxWChN0zA4Ih4VrMYtta29gBM3Nep4/COPnkPIfr1GV9ePABuuuPj42dmfEHo+anXBID0esZnSgWAcgWAq3k8qSR7yjd5l7CABBQADagDHWAATIElsAWOwBV4Ah8QAEJABIgFiwAPJIN0tPKlYAVYCwpAEdgMtoNysAfsB4fBMXACNIIz4CK4Am6AW+AueAh6wQB4CUbABzAGQRAeokBUSB3ShYwgC8gWYkLukA8UBIVBsVA8lASJICm0AloHFUElUDm0D6qGfoFOQxeha1AndB/qg4agt9AXGIHJMA3Who3h2TATZsGBcAS8EE6Cl8C5cD68ES6Dq+CjcAN8Eb4B34V74ZfwKAIQOYSO6CGWCBNhIyFIHJKISJBVSCFSilQhtUgz0obcRnqRYeQzBoehYhgYS4wrxh8TieFhlmBWYYox5ZjDmAZMK+Y2pg8zgvmOpWC1sBZYFywHG4NNwi7FFmBLsQex9djL2LvYAewHHA5Hx5ngnHD+uFhcCm45rhi3C1eHu4DrxPXjRvF4vDreAu+GD8Fz8Vn4AvxO/FH8eXwXfgD/iSBH0CXYEnwJcQQRIY9QSjhCOEfoIjwnjBEViUZEF2IIkU9cRtxEPEBsJt4kDhDHSEokE5IbKYKUQlpLKiPVki6THpHeycnJ6cs5y82TE8qtkSuTOy53Va5P7jNZmWxOZpMXkKXkjeRD5Avk++R3FArFmOJJiaNkUTZSqimXKE8on+Sp8lbyHHm+/Gr5CvkG+S75VwpEBSMFlsIihVyFUoWTCjcVhhWJisaKbEWu4irFCsXTij2Ko0pUJRulEKV0pWKlI0rXlAaV8crGyj7KfOV85f3Kl5T7qQjVgMqm8qjrqAeol6kDNBzNhMahpdCKaMdoHbQRFWUVe5UolRyVCpWzKr10hG5M59DT6JvoJ+jd9C+q2qosVYHqBtVa1S7Vj2qaap5qArVCtTq1u2pf1BnqPuqp6lvUG9Ufa2A0zDXmaSzV2K1xWWNYk6bpqsnTLNQ8oflAC9Yy1wrTWq61X6tda1RbR9tPW6y9U/uS9rAOXcdTJ0Vnm845nSFdqq67rlB3m+553RcMFQaLkcYoY7QyRvS09Pz1pHr79Dr0xvRN9CP18/Tr9B8bkAyYBokG2wxaDEYMdQ2DDVcY1hg+MCIaMY2SjXYYtRl9NDYxjjZeb9xoPGiiZsIxyTWpMXlkSjH1MF1iWmV6xwxnxjRLNdtldsscNncwTzavML9pAVs4Wggtdll0zsLOcp4lmlU1q8eSbMmyzLasseyzolsFWeVZNVq9mm04O272ltlts79bO1inWR+wfmijbBNgk2fTbPPW1tyWZ1the8eOYudrt9quye6NvYW9wH63/T0HqkOww3qHFodvjk6OEsdaxyEnQ6d4p0qnHiaNGcosZl51xjp7Oa92PuP82cXRJcvlhMtrV0vXVNcjroNzTOYI5hyY0++m78Z12+fW685wj3ff697roefB9ajyeOpp4Mn3POj5nGXGSmEdZb3ysvaSeNV7fWS7sFeyL3gj3n7ehd4dPso+kT7lPk989X2TfGt8R/wc/Jb7XfDH+gf6b/Hv4WhzeJxqzkiAU8DKgNZAcmB4YHng0yDzIElQczAcHBC8NfjRXKO5ormNISCEE7I15HGoSeiS0F/n4eaFzquY9yzMJmxFWFs4NXxx+JHwDxFeEZsiHkaaRkojW6IUohZEVUd9jPaOLonujZkdszLmRqxGrDC2KQ4fFxV3MG50vs/87fMHFjgsKFjQvdBkYc7Ca4s0FqUtOrtYYTF38cl4bHx0/JH4r9wQbhV3NIGTUJkwwmPzdvBe8j352/hDAjdBieB5oltiSeJgklvS1qShZI/k0uRhIVtYLnyT4p+yJ+VjakjqodTxtOi0unRCenz6aZGyKFXUmqGTkZPRKbYQF4h7l7gs2b5kRBIoOZgJZS7MbMqioY1Ru9RU+oO0L9s9uyL709KopSdzlHJEOe3LzJdtWPY81zf35+WY5bzlLSv0Vqxd0beStXLfKmhVwqqW1Qar81cPrPFbc3gtaW3q2t/yrPNK8t6vi17XnK+dvya//we/H2oK5AskBT3rXdfv+RHzo/DHjg12G3Zu+F7IL7xeZF1UWvS1mFd8/Sebn8p+Gt+YuLFjk+Om3Ztxm0Wbu7d4bDlcolSSW9K/NXhrwzbGtsJt77cv3n6t1L50zw7SDumO3rKgsqadhjs37/xanlx+t8Kroq5Sq3JD5cdd/F1duz131+7R3lO058te4d57+/z2NVQZV5Xux+3P3v/sQNSBtp+ZP1cf1DhYdPDbIdGh3sNhh1urnaqrj2gd2VQD10hrho4uOHrrmPexplrL2n119Lqi4+C49PiLX+J/6T4ReKLlJPNk7SmjU5X11PrCBqhhWcNIY3Jjb1NsU+fpgNMtza7N9b9a/XrojN6ZirMqZzedI53LPzd+Pvf86AXxheGLSRf7Wxa3PLwUc+lO67zWjsuBl69e8b1yqY3Vdv6q29Uz11yunb7OvN54w/FGQ7tDe/1vDr/Vdzh2NNx0utl0y/lWc+ecznNdHl0Xb3vfvnKHc+fG3bl3O7sju+/1LOjpvce/N3g/7f6bB9kPxh6ueYR9VPhY8XHpE60nVb+b/V7X69h7ts+7r/1p+NOH/bz+l39k/vF1IP8Z5Vnpc93n1YO2g2eGfIduvZj/YuCl+OXYcMGfSn9WvjJ9deq15+v2kZiRgTeSN+Nvi9+pvzv03v59y2jo6JMP6R/GPhZ+Uv90+DPzc9uX6C/Px5Z+xX8t+2b2rfl74PdH4+nj42KuhDvZCiCowomJALw9hPYJsQBQb6H9w/ypfnpSoKl/gEkC/4mneu5JcQSgFjUTbRH7AgDHUTVGlYK+T7REEZ4AtrOT6XTvO9mnTwgO/WPZO+nvouesAf+QqR7+L3X/04KJrPbgn/Zf7wYFbArrbikAAAA4ZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAKgAgAEAAAAAQAAAk2gAwAEAAAAAQAAAbcAAAAAQ7v38wAAMxpJREFUeAHt3QeUFdXhx/E/sHTpHaVGRZoBgdBUUGpcwJYgIkQjAgYFURCWRBCI9JqIIhgFRYo5B4nGRWkqkY4QVKrxhN6VjrjAwv8n92QyebtveY+30977vvM/78zcOzP3zucSf/875W2Oy5cv/x8fBBBAAAEE4lQgZ5yeF6eFAAIIIIDATwLkHP8OEEAAAQTiWYCci+fR5dwQQAABBMg5/g0ggAACCMSzADkXz6PLuSGAAAIIkHP8G0AAAQQQiGcBci6eR5dzQwABBBAg5/g3gAACCCAQzwLkXDyPLueGAAIIIEDO8W8AAfcEZs6cmcP2KVWqVPPmzT/88EMnevD3v/+9ffv2ZcqUyZMnT/HixVu0aDF79uwLFy6orV27dqkX48ePz8Z2V61aNXTo0BMnTmTjMTkUAtkiQM5lCyMHQSAKgRkzZqxevVrBMH369Fy5cimNlElR7H+1TfVjfr/97W87dOhw6dKliRMnLl269K233vr5z3/eq1evV1999Wp7X2O9TmfYsGHk3DXysZuTAklOHpxjI4BAJgK1atWqX7++qWjbtm2xYsXmzp2rtMtk06sVnTt3Ln/+/CFbjRs3ThNHpc6QIUOsKh1/wIAB3377rVWSXQvqQ758+bLraBwHgWwXYD6X7aQcEIEoBJQQuq6YO3duax/lU8OGDXWlsXDhwrfddtsbb7xh/7H1ypUrt2vX7r333qtbt6721cbWjmZBVybHjBlzyy23DB48OKSqbNmyt99+u71Qs70qVapcd911jRs3XrNmjVX1xRdfdOrUSW0pRPX98MMP796926o1V18XL178+OOP69JrgQIFBg0a9Pzzz2sDHc1cl/3ss8+s7VlAwFsB5nPe+tN6Igqkp6dfvHhR6XX48GHNvc6ePdu5c2cLQjfPevbsWbFiRZUoe3r37r1//377zGzjxo3btm174YUXFCoFCxa0djQLiqhjx451795deRNSFbL6yiuvKA4nT56scoXiPffcs3PnziJFimhVfahWrZqiTnF78ODBqVOnNmjQYOvWrSVLlrQOopBLTk6eNWuW+q/p6Q8//PDyyy8rgMuVK6dtatSoYW3JAgIeC+h/bHwQQMAdAd2ZC/kffN68eXXPLNPWFYeanA0fPrxEiRK602a2qVSpkm7p7dixI9NdVDhv3jw18dprr4XbQOXKM21Tu3ZtE7cqWbdunUp0+TTjXtrmzJkzCtQ//elPptacxW9+8xv7xgpsHUFHtheyjIAfBJjP6X+bfBBwVeDtt9+uXr26mvzuu+8WLFjw1FNPKdKefvpp04lPPvlk5MiR69evP3XqlNWtI0eO6MlJs3rrrbfefPPNVtU1L2g2psi0jqkF6+Kkgu2Pf/zj/PnzNbFT38w2mkTa23rwwQftqywj4FsBcs63Q0PH4lZAIWd/DkXpoidEunTpUrRoUc2rWrdurZcNXn/99RtuuEG37v72t7+NGDFCz3pYHObCoLUasmAueJoZW0hVyKqmiVaJppVatlrRddRly5bpYqYuV+o2oS6B6qqmVWv2yrob1pFZQMBzAXLO8yGgA4kuoPnZokWLvvnmm1/84he66qhnUvRGnfUEo3IuBCjrG29KUN1Ue//990eNGpX1liGHtVZPnjypDrz44ospKSmmMC0tTff8rA3MwrUdPOQgrCLgggDPW7qATBMIZCWwadMmVevBRX0rPJKSkqzLiZpC6UGPrHbOUKeYHDhw4Pbt23XhMaRSFz9XrlwZUphxVX3QPRUzwzO1f/nLX6yrlxm3NyUhM8Jwm1GOgPsCzOfcN6fFRBfYvHmzHu6Qwvfff68HFJcsWXL//ffr4UmV6J6ZnvXXZcMePXqoVj9ZYs+bCOH0iL/upWlCpqugOlSFChU0RfvHP/6h19L1HkLTpk2zPo4uVN555516rkRPV+qlguXLl+vdBl1TzXovPdWiDfSsyqOPPqqs1eOahQoVynoXahFwR4Ccc8eZVhD4r4B+rMSs6CF+xZuCTb9UYkruvvvuN998Uy/A6bXu66+/Xq8HlC5dulu3bv/dOYIlTcj0SKSyU8HWt2/f48ePK3Lq1Kmjw1pNZ32YOXPmPPPMM7prqDxWLiqJFcBZ76J7inqLTj+8ojuLejr0008/VUnWu1CLgDsCP12gcKclWkEAAQQQQMB9Ae7PuW9OiwgggAAC7gmQc+5Z0xICCCCAgPsC5Jz75rSIAAIIIOCeADnnnjUtIYAAAgi4L0DOuW9OiwgggAAC7gmQc+5Z0xICCCCAgPsCifv+nF7xOXDggN4r4ueL3P9nR4sIIIBANgroBbnTp0+XL18+Z85MJm+Jm3MKOf1ORDZCcygEEEAAAQ8F9u7dq18/z9iBxM0586NEctGvHGV0oQQBBBBAICgC+iNWmreE+6m5xM05c7lSIUfOBeWfMv1EAAEEshAIdxMqk0uZWRyFKgQQQAABBIIlQM4Fa7zoLQIIIIBAdALkXHRebI0AAgggECwBci5Y40VvEUAAAQSiEyDnovNiawQQQACBYAmQc8EaL3qLAAIIIBCdADkXnRdbI4AAAggES4CcC9Z40VsEEEAAgegEyLnovNgaAQQQQCBYAuRcsMaL3iKAAAIIRCdAzkXnxdYIIIAAAsESIOeCNV70FgEEEEAgOgFyLjovtkYAAQQQCJYAORes8aK3CCCAAALRCZBz0XmxNQIIIIBAsAQS9+/PZcs4VU5JDTnOrtHJISWsIoAAAgh4KMB8zkN8mkYAAQQQcFyAnHOcmAYQQAABBDwUIOc8xKdpBBBAAAHHBcg5x4lpAAEEEEDAQwFyzkN8mkYAAQQQcFyAnHOcmAYQQAABBDwUIOc8xKdpBBBAAAHHBcg5x4lpAAEEEEDAQwFyzkN8mkYAAQQQcFyAnHOcmAYQQAABBDwUIOc8xKdpBBBAAAHHBcg5x4lpAAEEEEDAQwFyzkN8mkYAAQQQcFyAnHOcmAYQQAABBDwUIOc8xKdpBBBAAAHHBcg5x4lpAAEEEEDAQwFyzkN8mkYAAQQQcFyAnHOcmAYQQAABBDwUIOc8xKdpBBBAAAHHBZzNuYsXL77wwgtVqlTJnz9/1apVhw8ffunSJXNOly9fHjp0aPny5VXVvHnzLVu2WOealpbWu3fvkiVLFixYsEOHDvv27bOqjh8/3rVr1yJXPlo4ceKEVbVnz5727dtrF+3Yp0+f8+fPW1UsIIAAAggkrICzOTdmzJjXXnttypQp27ZtGzt27Lhx415++WVjrdWJEyeqav369WXLlm3VqtXp06dNVd++fRcsWDBv3rwVK1acOXOmXbt26enppqpz586bNm36+MpHC4o6U64NkpOTz549q1204/z58/v162eq+EYAAQQQSGgBzauc+yh7Hn/8cev4DzzwQJcuXbSqWZ2ybfTo0abqxx9/1AxNiahVTdFy586trDJV+/fvz5kzp3JNq1u3btVQrVmzxlStXr1aq9u3b9fqwoULtZk2NlVz587NmzfvyZMnzWqm36rV7llvk+mO9sJKAz8M+T97LcsIIIAAAi4IZP3fc2fnc7fffvuyZcu++eYbJcqXX36pydY999yj5Z07dx46dKh169Za1keZ1KxZs1WrVml5w4YNFy5csKp0YbNWrVqmSsGmOGzYsOGVnf6vUaNGWrWqtJk2NlVt2rTRxU8dyqzyjQACCCCQsAJJjp75wIEDFbO33HJLrly5dGlxxIgRDz/8sFpUyOm7TJkyVuta3r17t6nKkydPsWLF7FVme32XLl3aKteCVq0q+9G0uw5iquzbK/z0MSWnTp2yV7GMAAIIIBCXAs7O595999133nlnzpw5GzdufOutt8aPH69vyzFHjhzWsia29lWrXAv2qpBtIqyyjjZq1Kgrj7D89FWhQgWrnAUEEEAAgXgVcDbnnn/++ZSUlE6dOtWuXVvPjDz77LNKGlHq5py+7fOtI0eOmAmZqvSopJ6rtMTtVYcPH7bKtXD06FFrL/vRtLsuftpneGavQYMGaX5pPnv37rUfimUEEEAAgbgUcDbnfvjhBz0eYsHp6qV5r0BvGijPlixZYqoUbMuXL2/SpIlW69Wrp+dQrKqDBw9u3rzZVDVu3FgRtW7dOrPX2rVrtWpVaTNtbKoWL16se346lFm1vlVY2PaxyllAAAEEEIhXAWfvz+mFNt2Tq1ixYs2aNf/5z3/qRQI9filKXX7UywMjR4686cpHCwUKFNA7A6rSFcVu3brprYASJUoUL168f//+mgu2bNlSVdWrV2/btm337t2nTZum1R49euiVg2rVqmlZz63UqFFDU0a9unDs2DHtpc2UaKrigwACCCCQyALO5pzelhs8eHCvXr107VEPQ/bs2XPIkCGGe8CAAefOnVOVrjHqEUrNwAoVKmSqJk2alJSU1LFjR23QokWLmTNnaiJoqmbPnq13wM3TmHqFXK/fmXJtkJqaqqM1bdpUL54rMnUv0FTxjQACCCCQyAI59ChHYp6/nrfU3FFXPmOZ9lVOSQ3R2zU6OaSEVQQQQAABRwWy/u/5f2+eOdoJDo4AAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkgA55xI0zSCAAAIIeCJAznnCTqMIIIAAAi4JkHMuQdMMAggggIAnAuScJ+w0igACCCDgkkCSS+0kUjOVU1Ltp7trdLJ9lWUEEEAAATcFmM+5qU1bCCCAAAJuC5BzbovTHgIIIICAmwLknJvatIUAAggg4LYAOee2OO0hgAACCLgpQM65qU1bCCCAAAJuC5BzbovTHgIIIICAmwLknJvatIUAAggg4LYAOee2OO0hgAACCLgpQM65qU1bCCCAAAJuC5BzbovTHgIIIICAmwLknJvatIUAAggg4LYAOee2OO0hgAACCLgpQM65qU1bCCCAAAJuC5BzbovTHgIIIICAmwLknJvatIUAAggg4LYAOee2OO0hgAACCLgpQM65qU1bCCCAAAJuC5BzbovTHgIIIICAmwLknJvatIUAAggg4LYAOee2OO0hgAACCLgp4HjO7d+/v0uXLiVKlChQoECdOnU2bNhgTu/y5ctDhw4tX758/vz5mzdvvmXLFuu009LSevfuXbJkyYIFC3bo0GHfvn1W1fHjx7t27VrkykcLJ06csKr27NnTvn177aId+/Tpc/78eauKBQQQQACBhBVwNucUS02bNs2dO/dHH320devWCRMmFC1a1FiPHTt24sSJU6ZMWb9+fdmyZVu1anX69GlT1bdv3wULFsybN2/FihVnzpxp165denq6qercufOmTZs+vvLRgqLOlGuD5OTks2fPahftOH/+/H79+pkqvhFAAAEEElkgh+ZVzp1/SkrKypUrP//885Am1KhmcsqzgQMHqkoTuDJlyowZM6Znz54nT54sVarUrFmzHnroIVUdOHCgQoUKCxcubNOmzbZt22rUqLFmzZqGDRuqSguNGzfevn17tWrVlKOKw7179+qwqlLUPfbYY0eOHClcuLBWM/2cOnVK00I1l8U2me5oL6yckmpf1fKu0ckhhSoJ2YZVBBBAAIFsFMj6v+fOzuc++OCD+vXr//rXvy5dunTdunVff/11c2I7d+48dOhQ69atzWrevHmbNWu2atUqrerC5oULF6wq5VatWrVM1erVq5VMJuS0ZaNGjbRqVWkzE3KqUigqO61rpKYVfatQHNbHKmcBAQQQQCBeBZzNuX//+99Tp0696aabFi1a9OSTT+q22dtvvy1KhZy+NYezWLVsCvWdJ0+eYsWKZVqlvLTKtaBVay/70bS7DmKq7NuPGjXqyq29n740TbRXsYwAAgggEJcCzubcpUuXbrvttpEjR2oyp2uS3bt3V+xZjjly5LCWdSXTvmqVa8FeFbJNhFXW0QYNGqQLleaji5xWOQsIIIAAAvEq4GzOlStXTnfULLvq1avrqUit6sETfdvnW7qXZiZkqtKjknqAxdrLXnX48GGrXAtHjx619rIfTbvr4qd9hmf20gVS3Y2zPvZDsYwAAgggEJcCzuacHrbcsWOHBffNN99UqlRJq1WqVFGeLVmyxFQp2JYvX96kSROt1qtXT89nWlUHDx7cvHmzqdJTJ5qKrVu3zuy1du1arVpV2kwbm6rFixcr0nQos8o3AggggEDCCiQ5eubPPvusckjXLTt27Kh8mn7loxZ1+VEPW6pct+700YLertM7A6rSnbNu3brprQC9cle8ePH+/fvXrl27ZcuWqtJ0sG3btrr4OW3aNK326NFDz1jqYUst67kVTRz1msG4ceOOHTumvbSZ5m2q4oMAAgggkMgCzuZcgwYN9Cac7ooNHz5cc7jJkyc/8sgjhnvAgAHnzp3r1auXrjHqEUrNwAoVKmSqJk2alJSUpGjUBi1atJg5c2auXLlM1ezZs/Uwi3kaU6+Q6/U7U64NUlNTdTTNIPXiuSJz/PjxpopvBBBAAIFEFnD2/Tk/y+rtAs0ddeUzlmlfyKtyOl/en/PzoNM3BBCIS4Gs/3vu7P25uATlpBBAAAEEAiRAzgVosOgqAggggEDUAuRc1GTsgAACCCAQIAFyLkCDRVcRQAABBKIWIOeiJmMHBBBAAIEACZBzARosuooAAgggELUAORc1GTsggAACCARIgJwL0GDRVQQQQACBqAXIuajJ2AEBBBBAIEAC5FyABouuIoAAAghELUDORU3GDggggAACARIg5wI0WHQVAQQQQCBqAXIuajJ2QAABBBAIkAA5F6DBoqsIIIAAAlELkHNRk7EDAggggECABMi5AA0WXUUAAQQQiFqAnIuajB0QQAABBAIkQM4FaLDoKgIIIIBA1ALkXNRk7IAAAgggECABci5Ag0VXEUAAAQSiFiDnoiZjBwQQQACBAAmQcwEaLLqKAAIIIBC1ADkXNRk7IIAAAggESICcC9Bg0VUEEEAAgagFyLmoydgBAQQQQCBAAuRcgAaLriKAAAIIRC1AzkVNxg4IIIAAAgESIOcCNFh0FQEEEEAgagFyLmoydkAAAQQQCJAAORegwaKrCCCAAAJRC5BzUZOxAwIIIIBAgATIuQANFl1FAAEEEIhagJyLmowdEEAAAQQCJEDOBWiw6CoCCCCAQNQC5FzUZOyAAAIIIBAgAXIuQINFVxFAAAEEohaINOeqVq36/fff2w9/4sQJFdpLWEYAAQQQQMBvApHm3K5du9LT0+29T0tL279/v72EZQQQQAABBPwmkHTVDn3wwQdmm0WLFhUpUsQsK/OWLVtWuXLlq+7OBggggAACCHgocPWcu++++9S/HDlyPProo1ZHc+fOrZCbMGGCVcICAggggAACPhS4es5dunRJ/a5Spcr69etLlizpw3OgSwgggAACCIQTuHrOmT137twZ7hCUI4AAAggg4FuBSHNOJ6AbcvocOXLEzPDMKb355pu+PTc6hgACCCCAQKQ5N2zYsOHDh9evX79cuXK6VwccAggggAACgRCINOdee+21mTNndu3aNRBnRScRQAABBBAwApG+P3f+/PkmTZqghgACCCCAQLAEIs25J554Ys6cOcE6N3qLAAIIIIBApNctf/zxx+nTpy9duvTWW2/Vy3MW3MSJE61lFhBAAAEEEPCbQKQ599VXX9WpU0e937x5s3UOPJBiUbCAAAIIIOBPgUhz7tNPP/XnCdArBBBAAAEEshCI9P5cFoegCgEEEEAAAd8KRDqfu+uuuzK9SvnJJ5/49tzoGAIIIIAAApHmnLk5Z7wuXLiwadMm3aiz/7IzlAgggAACCPhQINKcmzRpUkjvhw4deubMmZBCVhFAAAEEEPCVwLXfn+vSpQs/bumrsaQzCCCAAAIZBa4951avXp0vX76MR6QEAQQQQAAB/whEet3ygQcesDp9+fLlgwcPfvHFF4MHD7YKWUAAAQQQQMCHApHmXJEiRaze58yZs1q1avrzBa1bt7YKWUAAAQQQQMCHApHm3IwZM3zYe7qEAAIIIIBA1gKR5pw5yoYNG7Zt26YX6WrUqFG3bt2sD00tAggggAACngtEmnP6M+KdOnX67LPPihYtqvtzJ0+e1Jvj8+bNK1WqlOfnQAcQQAABBBAIJxDp85a9e/c+derUli1bjh07dvz4cb0krtU+ffqEOy7lCCCAAAII+EEg0vncxx9/rD/KU716ddNpXbd85ZVXeA7FD0NIHxBAAAEEshCIdD536dIl+5+d0xG1qsIsDk0VAggggAACngtEmnN33333M888c+DAAdPj/fv3P/vssy1atPD8BOgAAggggAACWQhEmnNTpkw5ffp05cqVf/azn914441VqlTR6ssvv5zFoalCAAEEEEDAc4FI789VqFBh48aNS5Ys2b59u5631P25li1bet57OoAAAggggEDWAlefz+kvzCnV9HSlDtSqVSs9eKnHLBs0aFCzZs3PP/8866NTiwACCCCAgLcCV8+5yZMnd+/evXDhwvaO6mfAevbsOXHiRHshywgggAACCPhN4Oo59+WXX7Zt2zZjv/VSgX4eJWM5JQgggAACCPhH4Oo5d/jw4ZA3Ckzvk5KSjh496p8zoScIIIAAAghkFLh6zl1//fVff/11xj2/+uqrcuXKZSzPtGTUqFH6Vcy+ffuaWj3Joj9HXr58+fz58zdv3lw/s2LtlZaWpluAJUuWLFiwYIcOHfbt22dV6XdYunbtqkum+mjhxIkTVtWePXvat2+vXbSjbh+eP3/eqmIBAQQQQCCRBa6ec/fcc8+QIUN+/PFHO9O5c+defPHFdu3a2QvDLa9fv3769Om33nqrtcHYsWN1b0/vKqiqbNmyerxFbymYWmXhggUL9MuZK1asOHPmjJpIT083VZ07d960aZN+mUUfLSjqTLk2SE5OPnv2rHbRjvPnz+/Xr5/VFgsIIIAAAokskENTq6zPX9ctb7vttly5cj399NP6s3OalulPFuhHv5QuetOgTJkyWe+urNLur7766ksvvVSnTh091aIWNZNTng0cOFD7agKng4wZM0YPtujnofXD0LNmzXrooYdUpdfS9T7DwoUL27Rpo0b12OeaNWsaNmyoKi00btxYLzmoSx999JHicO/evTqsqhR1jz32mH54OuTZGVXZP3qCVPNCtZj1ZvZdMi5XTkkNKdw1OjmkUCUh27CKAAIIIJCNAln/9/zq8zmF0KpVq2rVqjVo0KD777//vvvu+/3vf6/VlStXXjXkdBpPPfWUJlv2l+127tx56NAh67cx8+bN26xZMzWhjfVgy4ULF6wq5ZYaMlWrV69WLJmQ05aNGjXSqlWlzUzIqUqhqOzM9BkZlYvD+mhjPggggAAC8S0Q0XvilSpV0qRKt8e+/fZbzcZuuummYsWKReKiqZXmfLo4ad9YIadVe0Zqeffu3SpUVZ48eewHV5XZXt+lS5e2H0erVpX9aNpdBzFV9u21rNuEw4YNCylkFQEEEEAgjgUiyjlz/soPvR4euYUuJOonMRcvXpwvX76Me+n6p1Wo7LSvWuVasFeFbBNhlf1ompI+99xzpkSzOl0UtdeyjAACCCAQfwJXv255zeesK4e6SVavXj29gaDP8uXL//znP2vBzL3s8y1tZgr1TIoeldTE0WrUXqU7hVa5FvRWg7WX/WjaXRc/7TM8ay9dI9XdOOtjlbOAAAIIIBCvAg7mnP6agV5I0IOR5lO/fv1HHnlEy1WrVlWe6acyjamCTRHYpEkTrSoU9a6eVXXw4EH9QVdTpadO9MzIunXrzF5r167VqlWlzbSxqdIMUnmmQ5lVvhFAAAEEElkgiuuW0TIVKlRIj4dYe+nlthIlSpgSPWw5cuRI3efTRwsFChTQOwPaUo+WdOvWTW8FaMvixYv379+/du3a5hkW/YlX/SyLfoFs2rRp2rJHjx56xlIPW2pZz63oUUy9ZjBu3Dj9uXPtlfGHyqxusIAAAgggkFACDuZcFo4DBgzQG3i9evXSNUY9QqkZmELRbD9p0iRd2+zYsaM20Ixw5syZeqXBVM2ePVvvgJunMfUKuV6/M+XaIDU1VUdr2rSpXjxXZI4fPz6L1qlCAAEEEEgcgau/PxevFnoOhffn4nVwOS8EEEgogaz/e+7g/bmEUuZkEUAAAQT8KUDO+XNc6BUCCCCAQPYIkHPZ48hREEAAAQT8KUDO+XNc6BUCCCCAQPYIkHPZ48hREEAAAQT8KeDNewX+tHC0V/wRA0d5OTgCCCAQToD5XDgZyhFAAAEE4kGAnIuHUeQcEEAAAQTCCZBz4WQoRwABBBCIBwFyLh5GkXNAAAEEEAgnQM6Fk6EcAQQQQCAeBMi5eBhFzgEBBBBAIJwAORdOhnIEEEAAgXgQIOfiYRQ5BwQQQACBcALkXDgZyhFAAAEE4kGAnIuHUeQcEEAAAQTCCZBz4WQoRwABBBCIBwFyLh5GkXNAAAEEEAgnQM6Fk6EcAQQQQCAeBMi5eBhFzgEBBBBAIJwAORdOhnIEEEAAgXgQIOfiYRQ5BwQQQACBcALkXDgZyhFAAAEE4kGAnIuHUeQcEEAAAQTCCZBz4WQoRwABBBCIBwFyLh5GkXNAAAEEEAgnQM6Fk6EcAQQQQCAeBMi5eBhFzgEBBBBAIJwAORdOhnIEEEAAgXgQIOfiYRQ5BwQQQACBcALkXDgZyhFAAAEE4kGAnIuHUeQcEEAAAQTCCZBz4WQoRwABBBCIBwFyLh5GkXNAAAEEEAgnQM6Fk6EcAQQQQCAeBMi5eBhFzgEBBBBAIJwAORdOhnIEEEAAgXgQIOfiYRQ5BwQQQACBcALkXDgZyhFAAAEE4kGAnIuHUeQcEEAAAQTCCZBz4WQoRwABBBCIBwFyLh5GkXNAAAEEEAgnkBSugnKnBSqnpIY0sWt0ckgJqwgggAACMQown4sRkN0RQAABBHwtQM75enjoHAIIIIBAjALkXIyA7I4AAggg4GsBcs7Xw0PnEEAAAQRiFCDnYgRkdwQQQAABXwuQc74eHjqHAAIIIBCjADkXIyC7I4AAAgj4WoCc8/Xw0DkEEEAAgRgFyLkYAdkdAQQQQMDXAuScr4eHziGAAAIIxChAzsUIyO4IIIAAAr4WIOd8PTx0DgEEEEAgRgFyLkZAdkcAAQQQ8LUAOefr4aFzCCCAAAIxCpBzMQKyOwIIIICArwXIOV8PD51DAAEEEIhRgJyLEZDdEUAAAQR8LUDO+Xp46BwCCCCAQIwC5FyMgOyOAAIIIOBrAXLO18ND5xBAAAEEYhQg52IEZHcEEEAAAV8LkHO+Hh46hwACCCAQowA5FyMguyOAAAII+FqAnPP18NA5BBBAAIEYBci5GAHZHQEEEEDA1wLknK+Hh84hgAACCMQoQM7FCMjuCCCAAAK+FiDnfD08dA4BBBBAIEYBZ3Nu1KhRDRo0KFSoUOnSpe+7774dO3ZY3b18+fLQoUPLly+fP3/+5s2bb9myxapKS0vr3bt3yZIlCxYs2KFDh3379llVx48f79q1a5ErHy2cOHHCqtqzZ0/79u21i3bs06fP+fPnrSoWEEAAAQQSVsDZnFu+fPlTTz21Zs2aJUuWXLx4sXXr1mfPnjXWY8eOnThx4pQpU9avX1+2bNlWrVqdPn3aVPXt23fBggXz5s1bsWLFmTNn2rVrl56ebqo6d+68adOmj698tKCoM+XaIDk5WQfXLtpx/vz5/fr1M1V8I4AAAggkskCSoyevPLKOP2PGDM3qNmzYcOedd2oyN3ny5D/84Q8PPPCANnjrrbfKlCkzZ86cnj17njx58o033pg1a1bLli1V9c4771SoUGHp0qVt2rTZtm2bDqjUbNiwoapef/31xo0ba45YrVq1xYsXb926de/evZogqmrChAmPPfbYiBEjChcurFU+CCCAAAIJK+DsfM7OqgDTavHixfW9c+fOQ4cOaXpnNsibN2+zZs1WrVqlVQXhhQsXrCrlVq1atUzV6tWrdcHShJy2bNSokVatKm1mQk5VCkVd/NShzPGtbxWesn2schYQQAABBOJVwKWc0wTuueeeu/3225VGolTI6VtzOItVy6ZQ33ny5ClWrFimVZoRWuVa0Kq1l/1o2l0HMVX27XW/0Nzb07emifYqlhFAAAEE4lLApZx7+umnv/rqq7lz59oRc+TIYa0qCO2rVrkW7FUh20RYZR1t0KBBmlaajy5yWuUsIIAAAgjEq4AbOaeHJz/44INPP/30hhtuMI568EQL9vnWkSNHzIRMVXpUUs9VWuL2qsOHD1vlWjh69Ki1l/1o2l0XP+0zPLOXLpDqjp31sR+KZQQQQACBuBRwNuc039JM7r333vvkk0+qVKliCWpZeaaHME2Jgk1PZjZp0kSr9erVy507t1V18ODBzZs3myo9daKp2Lp168xea9eu1apVpc20sanSYymKNB3KrPKNAAIIIJCwAs4+b6mXCvQU5fvvv69X6Mx8SzfG9MKcLj/q5YGRI0fedOWjhQIFCuidAQ2DNujWrZveCihRooQeWunfv3/t2rXNs5fVq1dv27Zt9+7dp02bpi179OihVw70sKWW9dxKjRo19JrBuHHjjh07pr20meZtCTuunDgCCCCAgBFwNuemTp2qZvQauMWttwv0xL9WBwwYcO7cuV69eukaox6h1AxMWWg2mzRpUlJSUseOHbVBixYtZs6cmStXLlM1e/ZsvQNunsbUK+R6/c6Ua4PU1FQdrWnTpspRReb48eNNFd8IIIAAAoks4GzO6bplOFxN6fR7KPpk3CBfvnwvX/lkrNIMT2/UZSxXScWKFT/88MNMqyhEAAEEEEhYAWfvzyUsKyeOAAIIIOATAXLOJwNBNxBAAAEEHBEg5xxh5aAIIIAAAj4RIOd8MhB0AwEEEEDAEQFyzhFWDooAAggg4BMBcs4nA0E3EEAAAQQcESDnHGHloAgggAACPhEg53wyEHQDAQQQQMARAXLOEVYOigACCCDgEwFyzicDQTcQQAABBBwRIOccYeWgCCCAAAI+ESDnfDIQdAMBBBBAwBEBcs4RVg6KAAIIIOATAXLOJwNBNxBAAAEEHBEg5xxh5aAIIIAAAj4RIOd8MhB0AwEEEEDAEQFyzhFWDooAAggg4BMBcs4nA0E3EEAAAQQcESDnHGHloAgggAACPhEg53wyEHQDAQQQQMARgSRHjspBr1WgckpqyK67RieHlLCKAAIIIBC5APO5yK3YEgEEEEAgeALkXPDGjB4jgAACCEQuQM5FbsWWCCCAAALBEyDngjdm9BgBBBBAIHIBci5yK7ZEAAEEEAieADkXvDGjxwgggAACkQuQc5FbsSUCCCCAQPAEyLngjRk9RgABBBCIXICci9yKLRFAAAEEgidAzgVvzOgxAggggEDkAuRc5FZsiQACCCAQPAFyLnhjRo8RQAABBCIXIOcit2JLBBBAAIHgCZBzwRszeowAAgggELkAORe5FVsigAACCARPgJwL3pjRYwQQQACByAXIucit2BIBBBBAIHgC5FzwxoweI4AAAghELkDORW7FlggggAACwRMg54I3ZvQYAQQQQCByAXIuciu2RAABBBAIngA5F7wxo8cIIIAAApELJEW+KVt6JVA5JdXe9K7RyfZVlhFAAAEEshBgPpcFDlUIIIAAAoEXYD4X1CFkkhfUkaPfCCDgrgDzOXe9aQ0BBBBAwF0B5nPuejvZWsgMT01xJ89Jb46NAALBEGA+F4xxopcIIIAAAtcmQM5dmxt7IYAAAggEQ4DrlsEYp2vuZaYXM0MKzeXNjIUhJeoDF0KveSDYEQEEvBJgPueVPO0igAACCLghQM65oUwbCCCAAAJeCZBzXsnTLgIIIICAGwLcn3NDOZ7a4KZdPI0m54JAIggwn0uEUeYcEUAAgcQVIOcSd+w5cwQQQCARBMi5RBhlzhEBBBBIXAFyLnHHnjNHAAEEEkGAnEuEUeYcEUAAgcQVIOcSd+w5cwQQQCARBMi5RBhlzhEBBBBIXAFyLnHHnjNHAAEEEkGAnEuEUeYcEUAAgcQV4PdQEnfss/HMQ34khT9rkI22HAoBBGIUYD4XIyC7I4AAAgj4WoD5nK+HJ9CdY5IX6OGj8wjEjQDzubgZSk4EAQQQQCATAXIuExSKEEAAAQTiRoDrlnEzlAE4kZArmeoxT6wEYNjoIgIBF4irnHv11VfHjRt38ODBmjVrTp48+Y477gj46CRE9zMNv5BCE4eZFiaEESeJAAIxCMRPzr377rt9+/ZV1DVt2nTatGm//OUvt27dWrFixRhw2NXvAiHJp+4yQfT7mNE/BFwXiJ+cmzhxYrdu3Z544gkZajK3aNGiqVOnjho1ynVSGvRYINPwCykMN0EM2UxnQnB6PJw0j0DMAnGSc+fPn9+wYUNKSooF0rp161WrVlmrLCBwzQKZhl9IYbjgvOZG2REBBLJLIE5y7rvvvktPTy9TpozlouVDhw5Zq2Yh7crHLJ88eVILp06dCtkmqtVLaT+EbK8DhhSaJjIWhpSYzkRSyAGNeUZqHxrWenFRyL+QzcPaRFKozbRjyJYR7qsdM24Z3AOGALKKQEYB81/Fy5cvZ6z6qUQVcfDZv3+/zkUTOOtcXnrppWrVqlmrZuHFF1/MXIFSBBBAAIGAC+zduzfkv/lmNU7mcyVLlsyVK5d9AnfkyBH79M4M36BBg5577jmzfOnSpWPHjpUoUSJHjhwxDq7+X4kKFSqIuHDhwtahMhZmLNHGsRTGsm+mTXNAM3yxOMSyL4MSuz+GgTY0nb+Gb+XZ6dOny5cvn+m+cZJzefLkqVev3pIlS+6//35znlq+9957Q84575WPVVi0aFFrOfYFhZw958wBMxZmLNGWsRTGsm+mTXPAcGOXKVemhRhiaASicuCfjR0t2uUiRYqE2yVOck6np4la165d69ev37hx4+nTp+/Zs+fJJ58Md9qUI4AAAggkiED85NxDDz30/fffDx8+XO+J16pVa+HChZUqVUqQUeQ0EUAAAQTCCeQaOnRouLrAlTdo0ECvig8ePLhnz54uh5zuDjZv3jwp6X/+/4aMhRlLhBxLYSz7Zto0BzT/7GNxiGVfBiV2fwwDbWg6n73fOXT7LnuPyNEQQAABBBDwjwB/r8A/Y0FPEEAAAQSyX4Ccy35TjogAAggg4B8Bcs4/Y0FPEEAAAQSyX4Ccy35TjogAAggg4B8Bcs4/Y0FPEEAAAQSyX4Ccy35TjogAAggg4B8Bcs4/Y0FPEEAAAQSyX4Ccy35TjogAAggg4B8Bcs4/Y0FPEEAAAQSyX4Ccy35TjohAtAL604n6tbC2bdtmvaN+pa9OnTpZb5Np7Weffaa/P2X/vPDCC9rSKs+ZM6d+7r1u3boDBgzQL8RaB7G3qGVzBG2sP4DyyCOP6G9RWVuygIBvBcg53w4NHUsggTfffLN3794rVqzQ39nI9LT1+3wXL17MtCrywh07dijDzCclJcXaUeUHDhxYv379wIEDly5dqp9B//rrr61a+0LNmjW1+759+959911t07FjR3stywj4U4Cc8+e40KsEEjh79uxf//rX3/3ud+3atZs5c6Z15maytWjRIv21Kf3lxFmzZg0bNuzLL780kyr7ltYuWS+ULl267H8+1113nbWxKb/55ps7deq0cuXKUqVKqTNWrX1Bv1SuA2gyd8cdd3Tv3n3NmjX6u7L2DVhGwIcC5JwPB4UuJZaA5kbVrny6dOkyY8aMkJ9W14XEUaNGbdu2rXXr1v369TMzKk2q9IeonGDKnz+//nCj0u7IkSNZHP/QoUPvvfeerrXqk8VmVCHgB4H/+TsyfugQfUAg0QTeeOMNJZzOWvfnzpw5s2zZspYtW1oI+pOKrVq1MquahJkZlVUb1cINN9xgbb979+4SJUpYq/aFW265Rau7du3SPM9ermVdq1QfLl26dO7cOa326dOnYMGCIduwioDfBJjP+W1E6E9iCeje2Lp163TBUKetDNMsTffq7AS6aGlfDbf8+eefK4HMZ/bs2Zlupm02/edTrFixTLdRoZlQ6upoxg007dQBdCdvxIgReiJG3xm3oQQBvwkwn/PbiNCfxBLQZE4PmFx//fXmtJUxuXPnPn78uJVDEU6YFIdKIHOQMmXKZIpYpUqVokWLZlplL9Q1Uq1WrlzZXmiW8+TJc+ONN2pZl0//9a9/6Tae7hpm3IwSBHwlwHzOV8NBZxJLQAn39ttvT5gw4T+zrE16zKRSpUrhJmSKmfT09EyNdF9NCWQ+hQoVynSbSAp1QXL69Ol33nmnnkbJevvBgwfPnTt348aNWW9GLQKeC5Bzng8BHUhcgQ8//FBTt27duulRfuvzq1/9SpO8TFE0x9q5c6dC8bvvvktLS8t0m2so1CMneq5E87N58+Y1bdpUB586depVj1O1atV77713yJAhV92SDRDwVoCc89af1hNaQHmmR070grZd4cEHH1SSZTpPUpWeVbnrrrs02dJcyr5XLMu666ZXBerVqzd69Gj1Z/PmzTVq1IjkgHr+MzU1de3atZFszDYIeCWQI+QhZq/6QbsIIIAAAgg4IcB8zglVjokAAggg4BcBcs4vI0E/EEAAAQScECDnnFDlmAgggAACfhEg5/wyEvQDAQQQQMAJAXLOCVWOiQACCCDgFwFyzi8jQT8QQAABBJwQIOecUOWYCCCAAAJ+ESDn/DIS9AMBBBBAwAkBcs4JVY6JAAIIIOAXAXLOLyNBPxBAAAEEnBAg55xQ5ZgIIIAAAn4RIOf8MhL0AwEEEEDACYH/B4M0LcynwuRKAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3000 ORD MAX \n",
    "# The whole process\n",
    "\n",
    "## Preprocess\n",
    "In the beginning we decided the features we wanted to use amd therefore we decided to remove some of the colums because they were not necesarry for our predictions. The more data the longer time it takes to process and the data may become more inaccurate. We decided to drop NaN values as well.\n",
    "\n",
    "\n",
    "### Why are we dropping \n",
    "\n",
    "It's worth noting that dropping rows with NaN values might lead to a loss of data. We have consider other methods, such as filling NaNs with mean, median, or a specific value, depending on the nature of the data. But we chose to remove them. \n",
    "\n",
    "The code drops columns using irrelevante_col to streamline the dataset for analysis. Columns are removed if they are irrelevant, have many missing values, contain redundant information, or exhibit inconsistencies. The decision is tailored to the analysis goals, aiming for a cleaner dataset that meets specific requirements and enhances overall data quality. As well as more uncessasary data can cause inaccurate results and a longer runtime. \n",
    "\n",
    "### Visulization of NaN values \n",
    "\n",
    "We are cleaning and preparing the data for it to be used. Here is a visulasation of a bar chart that visually represents the impact of dropping rows with missing values (NaN) in our DataFrame. \n",
    "We see that the count of missing values significantly decreases after dropping rows, it indicates that this operation is effective in reducing missing data. If there was not a masjor change it can be considered effective in maintaining data integrity. But as we can see it was amsrat move. \n",
    "Dropping rows can also be computationally efficient, especially our dataset is large and the proportion of rows with missing values is relatively small. So even of there was a lot of data that is not used now it is a small amount compared to the whole dataset. \n",
    "Of couse dropping values and its outcome depends on the dataset but considering this exaple we thought the smartest move was to remove to remove the values. \n",
    "\n",
    "The significant reduction in missing values post-removal indicates the effectiveness of this operation with minimal impact on data integrity.\n",
    "The computational efficiency of dropping rows is highlighted, especially for large datasets, where the loss is negligible compared to the dataset's overall size.\n",
    "\n",
    "### Fish types and why we chose the fish we did \n",
    "Concentrating on the \"Art FAO\" column, we excluded other species, prioritizing the analysis of predominant fish types for accuracy.\n",
    "Here you can see a visulasation of the different fish types. As you can see there is a significant difference between the fishes. To get the best accuracy and values we chose to focus on the fish with the most data. \n",
    "Making a barchart of all fish to visualize\n",
    "\n",
    "### Why are we doing it?  \n",
    "\n",
    "## KNN\n",
    "When we used KNN we decided to normalize, it can be smart to normalize the featurtes because then no feature is very different from one another \n",
    "We are leverling out the feild for all features so the KNN works better and make even more accurate predictions  \n",
    "\n",
    "#### Confusion matrix in KNN \n",
    "The diagonal elements of the confusion matrix represent the correct predictions, while the off-diagonal elements represent the incorrect predictions.   \n",
    "A good model is one which has high correct predictions while few false predictions . The Blue ones that goes diagnonal are the correct predictions. As you can see there are a significant higher number of true predicttions. We have decided to predict this amount of different fish because we wantted the predictions to be fairly correct. \n",
    "\n",
    "You can see the numbers within the 300-400 value range. We have concluded that these might be difficult to differenciate because these species are different types of cod. And therefore might be more difficult to differenciate. Some of the squares that are similar in numbers that are not diagnonal are similar because sei and hyse is a type of torsk. And therefore you can seee it is more difficult to predict.\n",
    "##### Taking a look at the data \n",
    "If we look at the data we can see that there is more Torsk (cod) than there is Sei. Considering we have more data of Torsk than of Sei we can see that the data is more accurate for the Torsk. This is because it has more data to compare and can become even more accurate. And continuing. \n",
    "The training score is a little higher then validation, wich indicates a little overfitting.\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.85      0.85      5103\n",
    "           1       0.87      0.87      0.87      3693\n",
    "           2       0.99      0.99      0.99      2674\n",
    "           3       0.69      0.68      0.68      1497\n",
    "           4       0.92      0.88      0.90       494\n",
    "\n",
    "    accuracy                           0.86     13461\n",
    "   macro avg       0.86      0.85      0.86     13461\n",
    "weighted avg       0.86      0.86      0.86     13461\n",
    "\n",
    "\n",
    "## Supervised Logistic regression \n",
    "\n",
    "Pipeline: Streamlines preprocessing and modeling steps, ensuring that transformations are applied consistently during both training and evaluation.\n",
    "GridSearchCV: Automates the process of hyperparameter tuning and selects the best model configuration based on cross-validation performance. It also ensures your model is not just tuned to a specific subset of your data.\n",
    "Normalization included in Pipeline: Ensures that feature scaling (standardization) is properly integrated into the model training process, avoiding data leakage and ensuring that the same scaling is applied to both training and test data.\n",
    "\n",
    "\n",
    "#### Best Parameters Found\n",
    "\n",
    "- **`{'model__C': 10, 'model__solver': 'saga'}`**\n",
    "\n",
    "This line tells us the best combination of hyperparameters found via grid search cross-validation. The hyperparameter `C` is the inverse of regularization strength; smaller values specify stronger regularization. A `C` value of 10 indicates that a relatively lower amount of regularization was found to be optimal for the model, suggesting that your model benefits from allowing more flexibility without overfitting. The `solver` parameter indicates the algorithm to use in the optimization problem. For logistic regression, `saga` is an algorithm suitable for large datasets and supports L1 regularization, indicating it was the best choice for the data.\n",
    "\n",
    "#### Best Validation Accuracy\n",
    "\n",
    "- **0.6429509298901981**\n",
    "\n",
    "This number represents the highest accuracy achieved on the validation set during the model's training phase, using the best parameters found (`C=10` and `solver='saga'`). This accuracy value is a measure of how well the logistic regression model is at correctly predicting outcomes for data it hasn't been trained on, based on the split of data you provided for training and validation. An accuracy around 64.3% suggests that the model is significantly better than random guessing (which would be 50% in a binary classification task).\n",
    "\n",
    "#### Accuracy on Test Set\n",
    "\n",
    "- **0.6475001857217146**\n",
    "\n",
    "This is the accuracy of the model on the test set, which is data that was not seen by the model during training (including validation). This metric is crucial because it gives us an idea of how your model will perform on entirely new, unseen data. An accuracy of approximately 64.75% is consistent with the validation accuracy, suggesting that the model has generalized relatively well from the training/validation sets to the test set. This consistency is a good sign, indicating that your model hasn't overfitted to the training data and is capable of making predictions at a similar level of accuracy on unseen data.\n",
    "\n",
    "#### Precision, Recall, and F1 Score:\n",
    "\n",
    "Precision of **0.694** indicates that when the model predicts a class, it is correct approximately 69.4% of the time.\n",
    "Recall of 0.646 suggests that the model correctly identifies 64.6% of all relevant instances.\n",
    "\n",
    "F1 Score of 0.606, the harmonic mean of precision and recall, indicates a balance between them but also highlights a potential area for improvement. This balance is crucial in scenarios where both false positives and false negatives carry significant costs.\n",
    "\n",
    "ROC-AUC: A ROC-AUC score of 0.498 is very close to 0.5, which is the score expected from a model making predictions at random. This suggests the model is not effectively distinguishing between the classes for this specific task. A ROC-AUC score significantly higher than 0.5 is desirable as it indicates a good separation of classes by the model.\n",
    "\n",
    "Accuracy on Test Set: With an accuracy of 0.648 on the test set, the model's performance is consistent with the validation accuracy, suggesting that the model generalizes well to unseen data. However, considering the ROC-AUC score, this accuracy might not fully capture the model's predictive performance across different thresholds or the balance between sensitivity and specificity.\n",
    "\n",
    "\n",
    "## DL\n",
    "In our DL model we have used to_categorical to convert categorical data (like class labels) into a numerical format that can be used as input to a neural network model. The function is necessary when working with classification tasks, as most machine learning algorithms require numerical inputs. It helps in improving the performance of the model by representing categorical data in a suitable format for computation. \n",
    "\n",
    "The Epochs represents the number of times the entire dataset has been passed forward and backward through the neural network during training.\n",
    "Loss is a measure of how well the model is performing.The loss decreases over epochs, indicating that the model is improving. Higher accuracy values indicate better performance. Similar to loss, both training accuracy and validation accuracy are reported during training. The accuracy increases over epochs, indicating that the model is learning and making more accurate predictions.\n",
    "The validation loss and accuracy metrics give insights into how well the model is generalizing to new, unseen data.\n",
    "\n",
    "After training is complete, the model is evaluated on a separate test dataset to assess its performance on completely unseen data. The reported test accuracy tells us how well the model is expected to perform in the real world.\n",
    "\n",
    "The output tells us how the model's loss and accuracy change over training epochs, as well as how well it performs on both the validation and test datasets. Overall, the decreasing loss and increasing accuracy suggest that the model is learning and improving its performance as it trains.\n",
    "\n",
    "## Clustering \n",
    "With using clustering we want to check if the different types of fish is living in different places using the cordinates, and if this is one of the huge impacts on the other ML models we are using \n",
    "\n",
    "## Comparison\n",
    "#### KNN\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.85      0.85      5103\n",
    "           1       0.87      0.87      0.87      3693\n",
    "           2       0.99      0.99      0.99      2674\n",
    "           3       0.69      0.68      0.68      1497\n",
    "           4       0.92      0.88      0.90       494\n",
    "\n",
    "    accuracy                           0.86     13461\n",
    "   macro avg       0.86      0.85      0.86     13461\n",
    "weighted avg       0.86      0.86      0.86     13461\n",
    "\n",
    "#### Supervised Logistic regression \n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0       0.59      0.81      0.68      5103\n",
    "           1       0.71      0.59      0.65      3693\n",
    "           2       0.72      0.81      0.76      2674\n",
    "           3       1.00      0.00      0.00      1497\n",
    "           4       0.57      0.48      0.52       494\n",
    "\n",
    "    accuracy                           0.65     13461\n",
    "   macro avg       0.72      0.54      0.52     13461\n",
    "weighted avg       0.69      0.65      0.61     13461\n",
    "\n",
    "\n",
    "\n",
    "Comparing Logistic Regression and KNN you can see that the results and the predictions for KNN are much higher. This is likely because KNN is better at handelig imbalanced features. KNN makes predictions based on the similarity of instances in the feature space, which can be advantageous in capturing complex patterns in the data.\n",
    "In contrast, Logistic Regression may struggle with imbalanced classes or non-linear relationships between features and the target variable, leading to lower precision and recall.\n",
    " If you take a look at out grapth og fish you can see that this is the case. There is a significant decrease in the 0-4 types. \n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "As you also have noticed the accuracy significantly higher in KNN. This obvisely suggest that KNN ie better at corretly classfiy instances in the datasat given. This is likely due to its ability to capture complex relationships and handle imbalanced class distributions effectively.\n",
    "\n",
    "KNN doesn't assume a specific functional form for the decision boundary between classes. Instead, it makes predictions based on the majority class among its nearest neighbors. Therefore it can capture non-linear relationships and adapt to complex data distributions.\n",
    "Logistic Regression, on the other hand, assumes a linear relationship between features and the log-odds of the target variable.\n",
    "If the decision boundary between classes is non-linear, Logistic Regression may struggle to accurately classify instances, leading to lower performance metrics. Witch might be the cause in our case. \n",
    "\n",
    "KNN's nearest neighbor approach allows it to effectively capture instances of minority classes if they are well-represented within their local neighborhoods. Logistic Regression on the other hand may struggle with imbalanced classes, especially if the decision boundary is non-linear, leading to lower precision and recall for minority classes.\n",
    "\n",
    "The results suggest that KNN outperforms Logistic Regression in this scenario, achieving higher precision, recall, F1-scores, and accuracy.\n",
    "KNN's ability to capture complex relationships, handle imbalanced classes, and adapt to non-linear decision boundaries likely contributes to its superior performance in this case.\n",
    "\n",
    "\n",
    "#### DL \n",
    "Epoch 1/10\n",
    "1683/1683 [==============================] - 15s 8ms/step - loss: 0.5455 - accuracy: 0.7820 - val_loss: 0.4324 - val_accuracy: 0.8260\n",
    "Epoch 2/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.4294 - accuracy: 0.8245 - val_loss: 0.3748 - val_accuracy: 0.8460\n",
    "Epoch 3/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3970 - accuracy: 0.8376 - val_loss: 0.3654 - val_accuracy: 0.8528\n",
    "Epoch 4/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3809 - accuracy: 0.8437 - val_loss: 0.3544 - val_accuracy: 0.8566\n",
    "Epoch 5/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3685 - accuracy: 0.8499 - val_loss: 0.3499 - val_accuracy: 0.8539\n",
    "Epoch 6/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3583 - accuracy: 0.8520 - val_loss: 0.3358 - val_accuracy: 0.8642\n",
    "Epoch 7/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3491 - accuracy: 0.8565 - val_loss: 0.3315 - val_accuracy: 0.8603\n",
    "Epoch 8/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3457 - accuracy: 0.8587 - val_loss: 0.3347 - val_accuracy: 0.8645\n",
    "Epoch 9/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3414 - accuracy: 0.8604 - val_loss: 0.3282 - val_accuracy: 0.8659\n",
    "Epoch 10/10\n",
    "1683/1683 [==============================] - 13s 8ms/step - loss: 0.3366 - accuracy: 0.8618 - val_loss: 0.3234 - val_accuracy: 0.8721\n",
    "\n",
    "421/421 - 2s - loss: 0.3234 - accuracy: 0.8721 - 2s/epoch - 4ms/step\n",
    "Test accuracy: 0.8720749020576477\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Throughout this comprehensive exploration into machine learning methodologies applied to our fisheries dataset, we have engaged a variety of approachesâ€”each offering unique insights and reflecting different aspects of the underlying data.\n",
    "\n",
    "### Key Findings and Methodological Insights:\n",
    "\n",
    "1. **Processing the data :**\n",
    "   - Our decision to selectively drop columns and handle NaN values by elimination was nacaserry for both accuracy, size and time. It made the analytical process and enhanced the accuracy and efficiency of the floowing models. This choice, though involving some loss of data, was justified by the sigificant reduction in missing values and minimal impact on data integrity, as evidenced by our visual analysis.\n",
    "\n",
    "2. **Performance:**\n",
    "   - The **K-Nearest Neighbors (KNN)** model exhibited superior performance across various metrics, including precision, recall, and F1-score. This suggests that KNN's non-parametric nature and its ability to capture complex, non-linear relationships between features made it particularly effective for our dataset, which features imbalanced classes and intricate patterns.\n",
    "   - **Logistic Regression**, while generally robust, struggled in this context due to the non-linear decision boundaries and class imbalances. The hyperparameter tuning highlighted an optimal less-regulated model, yet the overall effectiveness was moderate, indicating potential limitations of linear models for such complex datasets.\n",
    "   - Our **Deep Learning** model demonstrated impressive learning capabilities, as shown by the consistent improvement in loss and accuracy across epochs. This approach proved particularly adept at generalizing from training to unseen test data, achieving the highest accuracy of 87.21%.\n",
    "\n",
    "3. **Clustering Analysis:**\n",
    "   - The clustering helped us see pattarns in where different fish are found. This might explain why some of the models workex better for some species than others. This part of the study showed the importance abour area and where the fish live. It also showed the imporance of showing natural facors when we use models t predict things about them. \n",
    "\n",
    "### Final Thoughts:\n",
    "\n",
    "The process from preparing our data to using complex models has improved our ability to make predictions and has given us a better understanding of marine life. As we keep improving these models and methods, we see great potential for using them to help manage and conserve fish populations sustainably. This project shows how powerful machine learning can be in turning data into useful information, leading to decisions that make a real difference."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
